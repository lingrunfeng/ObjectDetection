#!/usr/bin/env python3
"""
éªŒè¯ YOLO æ ‡æ³¨æ–‡ä»¶çš„è´¨é‡å’Œå®Œæ•´æ€§
"""

import os
from pathlib import Path
import json

# ç±»åˆ«åˆ—è¡¨ï¼ˆåº”è¯¥ä¸ classes.txt ä¸€è‡´ï¼‰
CLASSES = ['red_rectangle', 'red_triangle', 'red_cube', 'blue_cube']

def validate_yolo_annotation(txt_file, image_path=None):
    """
    éªŒè¯å•ä¸ª YOLO æ ‡æ³¨æ–‡ä»¶
    
    Returns:
        (is_valid, errors, warnings, info)
    """
    errors = []
    warnings = []
    info = {}
    
    if not os.path.exists(txt_file):
        errors.append(f"æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {txt_file}")
        return False, errors, warnings, info
    
    # è¯»å–æ ‡æ³¨å†…å®¹
    with open(txt_file, 'r') as f:
        lines = f.readlines()
    
    info['annotation_count'] = len([l for l in lines if l.strip()])
    
    if info['annotation_count'] == 0:
        warnings.append(f"æ ‡æ³¨æ–‡ä»¶ä¸ºç©ºï¼ˆæ²¡æœ‰æ ‡æ³¨ä»»ä½•ç‰©ä½“ï¼‰")
    
    valid_annotations = 0
    invalid_lines = []
    
    for line_num, line in enumerate(lines, 1):
        line = line.strip()
        if not line:
            continue
        
        parts = line.split()
        if len(parts) != 5:
            invalid_lines.append(f"ç¬¬ {line_num} è¡Œæ ¼å¼é”™è¯¯: åº”è¯¥æœ‰5ä¸ªå€¼ï¼Œå®é™…æœ‰ {len(parts)} ä¸ª")
            continue
        
        try:
            class_id = int(parts[0])
            center_x = float(parts[1])
            center_y = float(parts[2])
            width = float(parts[3])
            height = float(parts[4])
            
            # æ£€æŸ¥ç±»åˆ«ID
            if class_id < 0 or class_id >= len(CLASSES):
                errors.append(f"ç¬¬ {line_num} è¡Œ: æ— æ•ˆçš„ç±»åˆ«ID {class_id}ï¼ˆåº”è¯¥åœ¨ 0-{len(CLASSES)-1} èŒƒå›´å†…ï¼‰")
                continue
            
            # æ£€æŸ¥åæ ‡å€¼ï¼ˆåº”è¯¥åœ¨ 0-1 èŒƒå›´å†…ï¼‰
            if not (0 <= center_x <= 1):
                errors.append(f"ç¬¬ {line_num} è¡Œ: center_x {center_x} è¶…å‡ºèŒƒå›´ [0, 1]")
            if not (0 <= center_y <= 1):
                errors.append(f"ç¬¬ {line_num} è¡Œ: center_y {center_y} è¶…å‡ºèŒƒå›´ [0, 1]")
            if not (0 <= width <= 1):
                errors.append(f"ç¬¬ {line_num} è¡Œ: width {width} è¶…å‡ºèŒƒå›´ [0, 1]")
            if not (0 <= height <= 1):
                errors.append(f"ç¬¬ {line_num} è¡Œ: height {height} è¶…å‡ºèŒƒå›´ [0, 1]")
            
            # æ£€æŸ¥è¾¹ç•Œæ¡†æ˜¯å¦åœ¨å›¾ç‰‡å†…
            x_min = center_x - width / 2
            x_max = center_x + width / 2
            y_min = center_y - height / 2
            y_max = center_y + height / 2
            
            if x_min < 0 or x_max > 1 or y_min < 0 or y_max > 1:
                warnings.append(f"ç¬¬ {line_num} è¡Œ: è¾¹ç•Œæ¡†è¶…å‡ºå›¾ç‰‡èŒƒå›´")
            
            # æ£€æŸ¥è¾¹ç•Œæ¡†å¤§å°ï¼ˆä¸èƒ½å¤ªå°ï¼‰
            if width < 0.01 or height < 0.01:
                warnings.append(f"ç¬¬ {line_num} è¡Œ: è¾¹ç•Œæ¡†å¤ªå°ï¼ˆwidth={width:.4f}, height={height:.4f}ï¼‰")
            
            valid_annotations += 1
            info[f'class_{class_id}'] = info.get(f'class_{class_id}', 0) + 1
            
        except ValueError as e:
            errors.append(f"ç¬¬ {line_num} è¡Œ: æ•°å€¼æ ¼å¼é”™è¯¯ - {e}")
            continue
    
    info['valid_annotations'] = valid_annotations
    if invalid_lines:
        errors.extend(invalid_lines)
    
    is_valid = len(errors) == 0
    return is_valid, errors, warnings, info

def check_dataset(dataset_dir, split='train'):
    """æ£€æŸ¥æ•´ä¸ªæ•°æ®é›†"""
    images_dir = Path(dataset_dir) / 'images' / split
    labels_dir = Path(dataset_dir) / 'lables' / split
    
    if not images_dir.exists():
        print(f"âŒ é”™è¯¯: å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {images_dir}")
        return False
    
    if not labels_dir.exists():
        print(f"âŒ é”™è¯¯: æ ‡æ³¨ç›®å½•ä¸å­˜åœ¨: {labels_dir}")
        return False
    
    # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    image_files = []
    for ext in ['.png', '.jpg', '.jpeg']:
        image_files.extend(images_dir.glob(f'*{ext}'))
    
    # è·å–æ‰€æœ‰æ ‡æ³¨æ–‡ä»¶
    label_files = list(labels_dir.glob('*.txt'))
    
    print(f"\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡ ({split}):")
    print(f"   å›¾ç‰‡æ•°é‡: {len(image_files)}")
    print(f"   æ ‡æ³¨æ–‡ä»¶æ•°é‡: {len(label_files)}")
    
    if len(image_files) != len(label_files):
        print(f"   âš ï¸  è­¦å‘Š: å›¾ç‰‡æ•°é‡å’Œæ ‡æ³¨æ–‡ä»¶æ•°é‡ä¸åŒ¹é…ï¼")
    
    # éªŒè¯æ¯ä¸ªæ ‡æ³¨æ–‡ä»¶
    total_errors = 0
    total_warnings = 0
    total_annotations = 0
    class_counts = {i: 0 for i in range(len(CLASSES))}
    
    print(f"\nğŸ” éªŒè¯æ ‡æ³¨æ–‡ä»¶...")
    
    for img_file in image_files:
        label_file = labels_dir / f"{img_file.stem}.txt"
        
        if not label_file.exists():
            print(f"   âš ï¸  ç¼ºå°‘æ ‡æ³¨æ–‡ä»¶: {label_file.name}")
            continue
        
        is_valid, errors, warnings, info = validate_yolo_annotation(label_file, img_file)
        
        if not is_valid:
            total_errors += len(errors)
            print(f"   âŒ {label_file.name}:")
            for err in errors[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªé”™è¯¯
                print(f"      - {err}")
            if len(errors) > 3:
                print(f"      ... è¿˜æœ‰ {len(errors) - 3} ä¸ªé”™è¯¯")
        
        if warnings:
            total_warnings += len(warnings)
            # ä¸æ˜¾ç¤ºè­¦å‘Šï¼Œåªç»Ÿè®¡
        
        total_annotations += info.get('valid_annotations', 0)
        for i in range(len(CLASSES)):
            class_counts[i] += info.get(f'class_{i}', 0)
    
    # æ±‡æ€»ç»Ÿè®¡
    print(f"\nâœ… éªŒè¯ç»“æœ:")
    print(f"   æ€»æ ‡æ³¨æ¡†æ•°: {total_annotations}")
    print(f"   é”™è¯¯æ•°é‡: {total_errors}")
    print(f"   è­¦å‘Šæ•°é‡: {total_warnings}")
    
    if total_errors == 0:
        print(f"   âœ… æ‰€æœ‰æ ‡æ³¨æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼")
    else:
        print(f"   âš ï¸  å‘ç° {total_errors} ä¸ªé”™è¯¯ï¼Œè¯·æ£€æŸ¥å¹¶ä¿®å¤")
    
    print(f"\nğŸ“‹ ç±»åˆ«ç»Ÿè®¡:")
    for i, class_name in enumerate(CLASSES):
        count = class_counts[i]
        print(f"   {i}: {class_name} - {count} ä¸ªæ ‡æ³¨æ¡†")
    
    return total_errors == 0

def visualize_annotations(dataset_dir, split='train', num_samples=3):
    """å¯è§†åŒ–å‡ ä¸ªæ ‡æ³¨æ–‡ä»¶çš„å†…å®¹"""
    labels_dir = Path(dataset_dir) / 'lables' / split
    images_dir = Path(dataset_dir) / 'images' / split
    
    label_files = list(labels_dir.glob('*.txt'))[:num_samples]
    
    print(f"\nğŸ“¸ æ ‡æ³¨æ–‡ä»¶ç¤ºä¾‹ ({split}):")
    for label_file in label_files:
        print(f"\n   {label_file.name}:")
        with open(label_file, 'r') as f:
            lines = f.readlines()
        
        for i, line in enumerate(lines[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ªæ ‡æ³¨
            parts = line.strip().split()
            if len(parts) == 5:
                class_id = int(parts[0])
                center_x, center_y = float(parts[1]), float(parts[2])
                width, height = float(parts[3]), float(parts[4])
                
                if class_id < len(CLASSES):
                    class_name = CLASSES[class_id]
                    print(f"      æ ‡æ³¨ {i}: {class_name} | ä¸­å¿ƒ=({center_x:.3f}, {center_y:.3f}) | å°ºå¯¸=({width:.3f}, {height:.3f})")
                else:
                    print(f"      æ ‡æ³¨ {i}: [æ— æ•ˆç±»åˆ«ID: {class_id}]")
        
        if len(lines) > 5:
            print(f"      ... è¿˜æœ‰ {len(lines) - 5} ä¸ªæ ‡æ³¨")

if __name__ == '__main__':
    import sys
    
    dataset_dir = Path(__file__).parent
    if len(sys.argv) > 1:
        dataset_dir = Path(sys.argv[1])
    
    print("=" * 60)
    print("ğŸ” YOLO æ ‡æ³¨æ–‡ä»¶éªŒè¯å·¥å…·")
    print("=" * 60)
    
    # æ£€æŸ¥ classes.txt
    classes_file = dataset_dir / 'classes.txt'
    if classes_file.exists():
        with open(classes_file, 'r') as f:
            file_classes = [line.strip() for line in f if line.strip()]
        if file_classes != CLASSES:
            print(f"\nâš ï¸  è­¦å‘Š: classes.txt ä¸­çš„ç±»åˆ«ä¸è„šæœ¬ä¸­çš„ä¸ä¸€è‡´")
            print(f"   è„šæœ¬ä¸­: {CLASSES}")
            print(f"   æ–‡ä»¶ä¸­: {file_classes}")
    
    # éªŒè¯è®­ç»ƒé›†
    train_ok = check_dataset(dataset_dir, 'train')
    
    # éªŒè¯éªŒè¯é›†
    val_ok = check_dataset(dataset_dir, 'val')
    
    # æ˜¾ç¤ºç¤ºä¾‹
    visualize_annotations(dataset_dir, 'train', num_samples=2)
    visualize_annotations(dataset_dir, 'val', num_samples=2)
    
    print("\n" + "=" * 60)
    if train_ok and val_ok:
        print("âœ… æ•°æ®é›†éªŒè¯é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒæ¨¡å‹äº†ã€‚")
    else:
        print("âš ï¸  æ•°æ®é›†å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯ã€‚")
    print("=" * 60)








